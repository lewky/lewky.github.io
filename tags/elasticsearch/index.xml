<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Elasticsearch - 标签 - Yulin Lewis' Blog</title><link>https://lewky.cn/tags/elasticsearch/</link><description>Elasticsearch - 标签 - Yulin Lewis' Blog</description><generator>Hugo -- gohugo.io</generator><managingEditor>1019175915@qq.com (雨临Lewis)</managingEditor><webMaster>1019175915@qq.com (雨临Lewis)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Wed, 08 Sep 2021 23:44:59 +0800</lastBuildDate><atom:link href="https://lewky.cn/tags/elasticsearch/" rel="self" type="application/rss+xml"/><item><title>Elasticsearch问题汇总</title><link>https://lewky.cn/posts/es-issues/</link><pubDate>Wed, 08 Sep 2021 23:44:59 +0800</pubDate><author>文章作者</author><guid>https://lewky.cn/posts/es-issues/</guid><description><![CDATA[<h2 id="前言">前言</h2>
<p>本文主要基于Elasticsearch 6.5.4版本：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">&lt;dependency&gt;
  &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt;
  &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt;
  &lt;version&gt;6.5.4&lt;/version&gt;
&lt;/dependency&gt;
</code></pre></td></tr></table>
</div>
</div>]]></description></item><item><title>ELK系列(5) - Logstash怎么分割字符串并添加新的字段到Elasticsearch</title><link>https://lewky.cn/posts/b37842a8.html/</link><pubDate>Sun, 12 May 2019 18:24:07 +0800</pubDate><author>文章作者</author><guid>https://lewky.cn/posts/b37842a8.html/</guid><description><![CDATA[<h2 id="问题">问题</h2>
<p>有时候我们想要在Logstash里对收集到的日志等信息进行分割，并且将分割后的字符作为新的字符来index到Elasticsearch里。假定需求如下：</p>
<p>Logstash收集到的日志字段<code>message</code>的值是由多个字段拼接而成的，分隔符是<code>;,;</code>，如下：</p>]]></description></item><item><title>ELK系列(1) - Elasticsearch + Logstash + Kibana + Log4j2快速入门与搭建用例</title><link>https://lewky.cn/posts/65db1615.html/</link><pubDate>Sat, 11 May 2019 21:14:33 +0800</pubDate><author>文章作者</author><guid>https://lewky.cn/posts/65db1615.html/</guid><description><![CDATA[<h2 id="前言">前言</h2>
<p>最近公司分了个ELK相关的任务给我，在一边学习一边工作之余，总结下这些天来的学习历程和踩坑记录。</p>
<p>首先介绍下使用ELK的项目背景：在项目的数据库里有个表用来存储消息队列的消费日志，这些日志用于开发者日后的维护。每当客户端生产一条消息并发送到消息队列后，就会插入一条对应的记录到数据库里。当这条消息被消费之后，又会更新数据库里对应的记录的几个column的值，比如status、updated_on这些常用的column。</p>
<p>由于客户每天生产消费的消息很多，导致数据库里的这个表里的数据很多，长年累月下来，会达到数以亿计。领导决定不再把这些消费日志保存到数据库，而是改为通过Log4j2 + ELK架构把这些日志保存到Elasticsearch里。</p>
<h2 id="elk简介">ELK简介</h2>
<p>ELk是<code>Elasticsearch + Logstash + Kibana</code>的缩写，ELK一般用来收集分布式架构下各个节点的日志，并进行统一地管理。</p>]]></description></item></channel></rss>