<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>分割大文件 - 标签 - Yulin Lewis' Blog</title><link>https://lewky.cn/tags/%E5%88%86%E5%89%B2%E5%A4%A7%E6%96%87%E4%BB%B6/</link><description>分割大文件 - 标签 - Yulin Lewis' Blog</description><generator>Hugo -- gohugo.io</generator><managingEditor>1019175915@qq.com (雨临Lewis)</managingEditor><webMaster>1019175915@qq.com (雨临Lewis)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sun, 02 Sep 2018 21:23:02 +0800</lastBuildDate><atom:link href="https://lewky.cn/tags/%E5%88%86%E5%89%B2%E5%A4%A7%E6%96%87%E4%BB%B6/" rel="self" type="application/rss+xml"/><item><title>通过split命令分割大文件</title><link>https://lewky.cn/posts/54434588.html/</link><pubDate>Sun, 02 Sep 2018 21:23:02 +0800</pubDate><author>文章作者</author><guid>https://lewky.cn/posts/54434588.html/</guid><description><![CDATA[<h2 id="场景">场景</h2>
<p>线上出了问题，我需要去查找log来定位问题，但是由于线上数据量庞大，这些log文件每过一个小时就会自动回滚一次，尽管如此，有的log文件依然达到了五六g以上的大小。</p>
<p>对于这种巨大的log文件，常用的一些文本编辑器诸如EditPlus、Notepad++就不用说了，打开几百m的文件都会很卡，上g的直接程序崩溃。虽然UltraEdit对于大文件的读取会友好一些，但打开这种五六g的文件时也会陷入长时间的无响应状态。</p>
<p>后来我又得知了一个看log神器——glogg，打开五六g的大文件速度很快，但是有个问题，就是只能读取文件，不能编辑文件。毕竟我不只是要查看log，有时候还要对这些有用的log信息进行编辑。最后还是决定先把大文件分割成数个小文件，再用UltraEdit来查看这些文件。</p>]]></description></item></channel></rss>